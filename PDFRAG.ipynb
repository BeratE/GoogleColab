{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "N3nvnuvqpCrt",
        "Owv4E_YNpF-g",
        "Mg13TaCU-YfG"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPrpSH/ryEe/I+b9wtn9lIr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BeratE/GoogleColab/blob/main/PDFRAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependency Management"
      ],
      "metadata": {
        "id": "N3nvnuvqpCrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install utilities\n",
        "!apt-get install poppler-utils tesseract-ocr"
      ],
      "metadata": {
        "id": "0MsvpvGVFXeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install langchain huggingface_hub sentence_transformers faiss-cpu unstructured chromadb Cython tiktoken unstructured[local-inference] -q\n",
        "!pip install torch==2.2.1 wrapt==1.11.0 pillow==10.1.0\n",
        "# Session Restart required because python dependency management is a mess!"
      ],
      "metadata": {
        "id": "aGhrZAYz9tz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Language Model"
      ],
      "metadata": {
        "id": "Owv4E_YNpF-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "from google.colab import userdata\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = userdata.get('HF_TOKEN')\n",
        "if \"HUGGINGFACEHUB_API_TOKEN\" not in os.environ:\n",
        "    os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass.getpass(\n",
        "        \"Please provide your HuggingFaceHub API Token: \")"
      ],
      "metadata": {
        "id": "ve5EBeNX9UPz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import HuggingFaceEndpoint\n",
        "llm = HuggingFaceEndpoint(repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\", temperature=0.1)"
      ],
      "metadata": {
        "id": "6Gpxt4XMo_nR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Google Drive"
      ],
      "metadata": {
        "id": "Mg13TaCU-YfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "id": "BnkmMQab8gHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Document Embedding"
      ],
      "metadata": {
        "id": "40XAdLSgpLzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from langchain.document_loaders import UnstructuredPDFLoader\n",
        "root = \"/content/gdrive/My Drive/Books/GameAIPro\"\n",
        "loaders = [UnstructuredPDFLoader(str(fn)) for fn in Path(root).glob('**/*.pdf')]\n",
        "loaders"
      ],
      "metadata": {
        "id": "lHdEeqkOcI3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "index = VectorstoreIndexCreator(\n",
        "    embedding=HuggingFaceEmbeddings(),\n",
        "    text_splitter=CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "    ).from_loaders(loaders)"
      ],
      "metadata": {
        "id": "y9oabqGIBUXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "chain = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                    chain_type=\"stuff\",\n",
        "                                    retriever=index.vectorstore.as_retriever(),\n",
        "                                    input_key=\"question\")"
      ],
      "metadata": {
        "id": "MLE-gcwobEbG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# QA"
      ],
      "metadata": {
        "id": "29aQWqEBpbeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "def wrap_text(text, width=110):\n",
        "    lines = text.split('\\n')\n",
        "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
        "    wrapped_text = '\\n'.join(wrapped_lines)\n",
        "    return wrapped_text"
      ],
      "metadata": {
        "id": "S_wvJfRK_5gd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = input('How can I help you?\\n\\n')\n",
        "while (prompt != \"quit\"):\n",
        "  answer = chain.invoke(prompt)\n",
        "  print(\"\\n\")\n",
        "  print(wrap_text(answer[\"result\"]))\n",
        "  prompt = input(\"\\n\")"
      ],
      "metadata": {
        "id": "W2M6l6-8kiE7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33bbf9b7-fbe7-44e3-b786-20a2eb28944b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How can I help you?\n",
            "\n",
            "What is the best strategy to implement enemy AI in a simple fighting game?\n",
            "\n",
            "\n",
            " The best strategy to implement enemy AI in a simple fighting game depends on the specific requirements and\n",
            "constraints of the game. If the battles are relatively simple and the NPC faces uniform challenges, static\n",
            "analysis approaches such as crafting rules or building decision trees can be sufficient. However, these\n",
            "approaches can be brittle when the NPC is faced with new or unforeseen situations. Alternatively, simulating\n",
            "battles multiple times and recording outcomes can provide an estimate of the NPC's chances of winning. More\n",
            "advanced approaches, such as using RL algorithms to fine-tune AI behavior, can adapt to make NPCs more\n",
            "competitive or collaborative, but require more game knowledge and coding effort. Ultimately, the choice of\n",
            "strategy will depend on the resources available and the desired level of AI complexity.\n",
            "\n",
            "quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bWKMqsNvBf-f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}